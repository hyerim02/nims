{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nims_academy_cnn.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"I20VzSPxSk4O","colab_type":"code","colab":{}},"cell_type":"code","source":["# 기본 import\n","import tensorflow \n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","# fashion-MNIST 데이터 import\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","# Keras MODEL 구축 import\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten\n","\n","# Keras MODEL 시각화 import\n","from IPython.display import SVG\n","from tensorflow.python.keras.utils.vis_utils import model_to_dot \n","\n","# 무시\n","# from jupyterthemes import jtplot \n","# jtplot.style()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iSysd_MRSoeV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"a4bb53b7-f65b-4abb-f8a3-577a8e5b29b9","executionInfo":{"status":"ok","timestamp":1551143240287,"user_tz":-540,"elapsed":7485,"user":{"displayName":"Sajune Park","photoUrl":"","userId":"07441539171935813777"}}},"cell_type":"code","source":["# 데이터 불러오기\n","(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n","\n","# 클래스 갯수 \n","nb_classes = 10\n","\n","# 데이터 전처리\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# 학습 데이터 셋을 학습 / 평가 셋으로 나눈다. (# 학습 셋: 55,000, 검증 셋: 5000)\n","(x_train, x_valid) = x_train[5000:], x_train[:5000] \n","(y_train, y_valid) = y_train[5000:], y_train[:5000]\n","\n","# 입력 이미지의 크기를 (28, 28) 에서 (28, 28, 1) 로 배열 차원을 변경(reshape)\n","w, h = 28, 28\n","x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n","x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n","x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n","\n","# 레이블에 원-핫 인코딩 적용 \n","# 원-핫 벡터는 단 하나의 차원에서만 1이고, 나머지 차원에서는 0인 벡터입니다.\n","y_train = to_categorical(y_train, 10)\n","y_valid = to_categorical(y_valid, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# 학습 셋 크기\n","print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n","\n","# 학습용, 검증용, 테스트용 데이터셋의 개수\n","print(x_train.shape[0], 'train set')\n","print(x_valid.shape[0], 'validation set')\n","print(x_test.shape[0], 'test set')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n","55000 train set\n","5000 validation set\n","10000 test set\n"],"name":"stdout"}]},{"metadata":{"id":"esNb6bkfStPD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":462},"outputId":"f6c2f5c7-9759-412a-9e19-601d5ea6b96a","executionInfo":{"status":"ok","timestamp":1551143245616,"user_tz":-540,"elapsed":1155,"user":{"displayName":"Sajune Park","photoUrl":"","userId":"07441539171935813777"}}},"cell_type":"code","source":["model = Sequential()\n","\n","model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","\n","model.add(Flatten()) # Flatten()은 이미지를 일차원으로 바꿔줍니다.\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(10, activation='softmax'))\n","\n","\n","model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n","print(model.summary())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 28, 28, 64)        320       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 14, 14, 128)       32896     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 6272)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               802944    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 837,450\n","Trainable params: 837,450\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"1j5Y_R6xS4f5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3451},"outputId":"0b47fa15-be17-490d-b4a3-95826ed49886","executionInfo":{"status":"ok","timestamp":1551145346182,"user_tz":-540,"elapsed":795115,"user":{"displayName":"Sajune Park","photoUrl":"","userId":"07441539171935813777"}}},"cell_type":"code","source":["epochs = 100\n","\n","model.fit(x_train, y_train, \n","                          epochs=epochs, \n","                          batch_size=64,\n","                          validation_data=(x_valid, y_valid))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Train on 55000 samples, validate on 5000 samples\n","Epoch 1/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.2000 - acc: 0.9281 - val_loss: 0.2521 - val_acc: 0.9114\n","Epoch 2/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.1972 - acc: 0.9279 - val_loss: 0.2600 - val_acc: 0.9094\n","Epoch 3/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.1932 - acc: 0.9293 - val_loss: 0.2482 - val_acc: 0.9114\n","Epoch 4/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.1911 - acc: 0.9307 - val_loss: 0.2756 - val_acc: 0.9000\n","Epoch 5/100\n","55000/55000 [==============================] - 8s 142us/sample - loss: 0.1881 - acc: 0.9323 - val_loss: 0.2704 - val_acc: 0.9058\n","Epoch 6/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1860 - acc: 0.9321 - val_loss: 0.2607 - val_acc: 0.9070\n","Epoch 7/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1829 - acc: 0.9331 - val_loss: 0.2434 - val_acc: 0.9136\n","Epoch 8/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1806 - acc: 0.9346 - val_loss: 0.2482 - val_acc: 0.9144\n","Epoch 9/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1795 - acc: 0.9351 - val_loss: 0.2723 - val_acc: 0.9056\n","Epoch 10/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1763 - acc: 0.9353 - val_loss: 0.2661 - val_acc: 0.9092\n","Epoch 11/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1728 - acc: 0.9373 - val_loss: 0.2659 - val_acc: 0.9098\n","Epoch 12/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1715 - acc: 0.9380 - val_loss: 0.2547 - val_acc: 0.9092\n","Epoch 13/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1686 - acc: 0.9384 - val_loss: 0.2440 - val_acc: 0.9172\n","Epoch 14/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.1669 - acc: 0.9392 - val_loss: 0.2580 - val_acc: 0.9076\n","Epoch 15/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1636 - acc: 0.9411 - val_loss: 0.2798 - val_acc: 0.9020\n","Epoch 16/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1611 - acc: 0.9417 - val_loss: 0.2753 - val_acc: 0.9046\n","Epoch 17/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1584 - acc: 0.9432 - val_loss: 0.2608 - val_acc: 0.9094\n","Epoch 18/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1559 - acc: 0.9436 - val_loss: 0.2662 - val_acc: 0.9076\n","Epoch 19/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.1549 - acc: 0.9439 - val_loss: 0.2778 - val_acc: 0.9054\n","Epoch 20/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1536 - acc: 0.9445 - val_loss: 0.2520 - val_acc: 0.9146\n","Epoch 21/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1507 - acc: 0.9456 - val_loss: 0.2521 - val_acc: 0.9140\n","Epoch 22/100\n","55000/55000 [==============================] - 8s 142us/sample - loss: 0.1494 - acc: 0.9456 - val_loss: 0.3027 - val_acc: 0.8932\n","Epoch 23/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.1460 - acc: 0.9475 - val_loss: 0.2686 - val_acc: 0.9104\n","Epoch 24/100\n","55000/55000 [==============================] - 8s 142us/sample - loss: 0.1437 - acc: 0.9478 - val_loss: 0.2687 - val_acc: 0.9102\n","Epoch 25/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.1411 - acc: 0.9490 - val_loss: 0.3376 - val_acc: 0.8828\n","Epoch 26/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1405 - acc: 0.9497 - val_loss: 0.2750 - val_acc: 0.9056\n","Epoch 27/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1387 - acc: 0.9499 - val_loss: 0.2453 - val_acc: 0.9176\n","Epoch 28/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.1348 - acc: 0.9519 - val_loss: 0.2670 - val_acc: 0.9124\n","Epoch 29/100\n","55000/55000 [==============================] - 8s 142us/sample - loss: 0.1345 - acc: 0.9518 - val_loss: 0.2609 - val_acc: 0.9134\n","Epoch 30/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1319 - acc: 0.9524 - val_loss: 0.2797 - val_acc: 0.9066\n","Epoch 31/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.1289 - acc: 0.9535 - val_loss: 0.3196 - val_acc: 0.8924\n","Epoch 32/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1277 - acc: 0.9535 - val_loss: 0.2604 - val_acc: 0.9166\n","Epoch 33/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1259 - acc: 0.9550 - val_loss: 0.2746 - val_acc: 0.9102\n","Epoch 34/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.1243 - acc: 0.9545 - val_loss: 0.2871 - val_acc: 0.9082\n","Epoch 35/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.1211 - acc: 0.9565 - val_loss: 0.2941 - val_acc: 0.9040\n","Epoch 36/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1201 - acc: 0.9569 - val_loss: 0.2582 - val_acc: 0.9162\n","Epoch 37/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.1172 - acc: 0.9585 - val_loss: 0.2667 - val_acc: 0.9148\n","Epoch 38/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.1177 - acc: 0.9574 - val_loss: 0.2913 - val_acc: 0.9062\n","Epoch 39/100\n","55000/55000 [==============================] - 8s 142us/sample - loss: 0.1127 - acc: 0.9597 - val_loss: 0.2628 - val_acc: 0.9172\n","Epoch 40/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.1109 - acc: 0.9601 - val_loss: 0.2653 - val_acc: 0.9162\n","Epoch 41/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.1091 - acc: 0.9614 - val_loss: 0.3030 - val_acc: 0.9084\n","Epoch 42/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.1092 - acc: 0.9605 - val_loss: 0.2569 - val_acc: 0.9178\n","Epoch 43/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.1059 - acc: 0.9620 - val_loss: 0.2710 - val_acc: 0.9158\n","Epoch 44/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.1052 - acc: 0.9627 - val_loss: 0.2550 - val_acc: 0.9188\n","Epoch 45/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.1031 - acc: 0.9632 - val_loss: 0.2761 - val_acc: 0.9112\n","Epoch 46/100\n","55000/55000 [==============================] - 8s 142us/sample - loss: 0.1004 - acc: 0.9646 - val_loss: 0.2854 - val_acc: 0.9118\n","Epoch 47/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.1003 - acc: 0.9632 - val_loss: 0.3091 - val_acc: 0.9054\n","Epoch 48/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0962 - acc: 0.9655 - val_loss: 0.3284 - val_acc: 0.9030\n","Epoch 49/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.0969 - acc: 0.9650 - val_loss: 0.3961 - val_acc: 0.8880\n","Epoch 50/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0939 - acc: 0.9667 - val_loss: 0.2726 - val_acc: 0.9160\n","Epoch 51/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.0924 - acc: 0.9672 - val_loss: 0.3115 - val_acc: 0.9076\n","Epoch 52/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0917 - acc: 0.9676 - val_loss: 0.2953 - val_acc: 0.9130\n","Epoch 53/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0886 - acc: 0.9689 - val_loss: 0.2720 - val_acc: 0.9162\n","Epoch 54/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0863 - acc: 0.9699 - val_loss: 0.2598 - val_acc: 0.9234\n","Epoch 55/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.0847 - acc: 0.9702 - val_loss: 0.2809 - val_acc: 0.9170\n","Epoch 56/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.0837 - acc: 0.9708 - val_loss: 0.3037 - val_acc: 0.9090\n","Epoch 57/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.0817 - acc: 0.9716 - val_loss: 0.2944 - val_acc: 0.9160\n","Epoch 58/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0807 - acc: 0.9718 - val_loss: 0.2823 - val_acc: 0.9178\n","Epoch 59/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0775 - acc: 0.9728 - val_loss: 0.2930 - val_acc: 0.9160\n","Epoch 60/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0782 - acc: 0.9732 - val_loss: 0.2728 - val_acc: 0.9210\n","Epoch 61/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.0756 - acc: 0.9730 - val_loss: 0.2997 - val_acc: 0.9138\n","Epoch 62/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0760 - acc: 0.9729 - val_loss: 0.3019 - val_acc: 0.9118\n","Epoch 63/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0750 - acc: 0.9736 - val_loss: 0.3261 - val_acc: 0.9142\n","Epoch 64/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0725 - acc: 0.9746 - val_loss: 0.3039 - val_acc: 0.9170\n","Epoch 65/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0696 - acc: 0.9760 - val_loss: 0.2923 - val_acc: 0.9210\n","Epoch 66/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0688 - acc: 0.9756 - val_loss: 0.2886 - val_acc: 0.9192\n","Epoch 67/100\n","55000/55000 [==============================] - 8s 148us/sample - loss: 0.0664 - acc: 0.9771 - val_loss: 0.3053 - val_acc: 0.9152\n","Epoch 68/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.0655 - acc: 0.9775 - val_loss: 0.3087 - val_acc: 0.9176\n","Epoch 69/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.0623 - acc: 0.9790 - val_loss: 0.2951 - val_acc: 0.9192\n","Epoch 70/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0648 - acc: 0.9771 - val_loss: 0.2946 - val_acc: 0.9210\n","Epoch 71/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0598 - acc: 0.9791 - val_loss: 0.3179 - val_acc: 0.9174\n","Epoch 72/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.0583 - acc: 0.9794 - val_loss: 0.3076 - val_acc: 0.9180\n","Epoch 73/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.0597 - acc: 0.9797 - val_loss: 0.3902 - val_acc: 0.9022\n","Epoch 74/100\n","55000/55000 [==============================] - 8s 147us/sample - loss: 0.0577 - acc: 0.9803 - val_loss: 0.3449 - val_acc: 0.9056\n","Epoch 75/100\n","55000/55000 [==============================] - 8s 146us/sample - loss: 0.0565 - acc: 0.9805 - val_loss: 0.3463 - val_acc: 0.9146\n","Epoch 76/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.0550 - acc: 0.9809 - val_loss: 0.3825 - val_acc: 0.9054\n","Epoch 77/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0529 - acc: 0.9828 - val_loss: 0.3182 - val_acc: 0.9128\n","Epoch 78/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0529 - acc: 0.9814 - val_loss: 0.3120 - val_acc: 0.9162\n","Epoch 79/100\n","55000/55000 [==============================] - 8s 146us/sample - loss: 0.0504 - acc: 0.9833 - val_loss: 0.3329 - val_acc: 0.9112\n","Epoch 80/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0495 - acc: 0.9832 - val_loss: 0.4230 - val_acc: 0.8952\n","Epoch 81/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0492 - acc: 0.9833 - val_loss: 0.4261 - val_acc: 0.9016\n","Epoch 82/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0473 - acc: 0.9837 - val_loss: 0.4053 - val_acc: 0.8984\n","Epoch 83/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0475 - acc: 0.9838 - val_loss: 0.3346 - val_acc: 0.9112\n","Epoch 84/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0441 - acc: 0.9860 - val_loss: 0.4440 - val_acc: 0.8900\n","Epoch 85/100\n","55000/55000 [==============================] - 8s 146us/sample - loss: 0.0432 - acc: 0.9853 - val_loss: 0.3486 - val_acc: 0.9130\n","Epoch 86/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0436 - acc: 0.9858 - val_loss: 1.5765 - val_acc: 0.8188\n","Epoch 87/100\n","55000/55000 [==============================] - 8s 147us/sample - loss: 0.0453 - acc: 0.9853 - val_loss: 0.3500 - val_acc: 0.9164\n","Epoch 88/100\n","55000/55000 [==============================] - 8s 146us/sample - loss: 0.0415 - acc: 0.9868 - val_loss: 0.3505 - val_acc: 0.9116\n","Epoch 89/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0385 - acc: 0.9879 - val_loss: 0.3349 - val_acc: 0.9184\n","Epoch 90/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0364 - acc: 0.9883 - val_loss: 0.3609 - val_acc: 0.9114\n","Epoch 91/100\n","55000/55000 [==============================] - 8s 147us/sample - loss: 0.0374 - acc: 0.9879 - val_loss: 0.3284 - val_acc: 0.9230\n","Epoch 92/100\n","55000/55000 [==============================] - 8s 147us/sample - loss: 0.0366 - acc: 0.9885 - val_loss: 0.3871 - val_acc: 0.9058\n","Epoch 93/100\n","55000/55000 [==============================] - 8s 149us/sample - loss: 0.0359 - acc: 0.9885 - val_loss: 0.3513 - val_acc: 0.9180\n","Epoch 94/100\n","55000/55000 [==============================] - 8s 146us/sample - loss: 0.0348 - acc: 0.9895 - val_loss: 0.3794 - val_acc: 0.9134\n","Epoch 95/100\n","55000/55000 [==============================] - 8s 145us/sample - loss: 0.0338 - acc: 0.9897 - val_loss: 0.3774 - val_acc: 0.9124\n","Epoch 96/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0330 - acc: 0.9896 - val_loss: 0.3508 - val_acc: 0.9166\n","Epoch 97/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0357 - acc: 0.9890 - val_loss: 0.5457 - val_acc: 0.8804\n","Epoch 98/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0328 - acc: 0.9904 - val_loss: 0.3621 - val_acc: 0.9158\n","Epoch 99/100\n","55000/55000 [==============================] - 8s 143us/sample - loss: 0.0297 - acc: 0.9911 - val_loss: 0.4816 - val_acc: 0.9028\n","Epoch 100/100\n","55000/55000 [==============================] - 8s 144us/sample - loss: 0.0299 - acc: 0.9907 - val_loss: 0.3525 - val_acc: 0.9202\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fb7c6412ef0>"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"Vl0gsTt8TAiC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"373b1916-e231-479b-a37a-dec6ef13b32e","executionInfo":{"status":"ok","timestamp":1551145630018,"user_tz":-540,"elapsed":1832,"user":{"displayName":"Sajune Park","photoUrl":"","userId":"07441539171935813777"}}},"cell_type":"code","source":["loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)\n","print('')\n","print('loss_and_metrics : ' + str(loss_and_metrics))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 1s 111us/sample - loss: 0.3970 - acc: 0.9116\n","\n","loss_and_metrics : [0.39695110666826366, 0.9116]\n"],"name":"stdout"}]},{"metadata":{"id":"FdD_YHEfWQ5a","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}